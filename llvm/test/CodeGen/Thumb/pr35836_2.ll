; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc < %s | FileCheck %s

target datalayout = "e-m:e-p:64:64-i128:64-v128:64:128-a:0:64-n64-S64"
target triple = "thumbv6---gnueabi"

; Function Attrs: norecurse nounwind readonly
define i128 @a(ptr nocapture readonly %z) {
; CHECK-LABEL: a:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    .save {r4, r5, r6, r7, lr}
; CHECK-NEXT:    push {r4, r5, r6, r7, lr}
; CHECK-NEXT:    .pad #20
; CHECK-NEXT:    sub sp, #20
; CHECK-NEXT:    ldr r1, [r0, #32]
; CHECK-NEXT:    str r1, [sp, #12] @ 4-byte Spill
; CHECK-NEXT:    ldr r1, [r0, #36]
; CHECK-NEXT:    str r1, [sp, #16] @ 4-byte Spill
; CHECK-NEXT:    ldr r2, [r0, #40]
; CHECK-NEXT:    ldr r3, [r0, #44]
; CHECK-NEXT:    ldr r4, [r0, #12]
; CHECK-NEXT:    ldm r0!, {r6, r7}
; CHECK-NEXT:    ldr r1, [r0]
; CHECK-NEXT:    subs r0, #8
; CHECK-NEXT:    adds r5, r1, r6
; CHECK-NEXT:    mov r5, r4
; CHECK-NEXT:    adcs r5, r7
; CHECK-NEXT:    ldr r5, [sp, #12] @ 4-byte Reload
; CHECK-NEXT:    adcs r2, r5
; CHECK-NEXT:    ldr r5, [sp, #16] @ 4-byte Reload
; CHECK-NEXT:    adcs r3, r5
; CHECK-NEXT:    adds r6, r1, r6
; CHECK-NEXT:    adcs r4, r7
; CHECK-NEXT:    ldr r1, [r0, #20]
; CHECK-NEXT:    str r1, [sp, #16] @ 4-byte Spill
; CHECK-NEXT:    ldr r5, [r0, #28]
; CHECK-NEXT:    ldr r1, [r0, #16]
; CHECK-NEXT:    ldr r7, [r0, #24]
; CHECK-NEXT:    adcs r7, r1
; CHECK-NEXT:    ldr r0, [sp, #16] @ 4-byte Reload
; CHECK-NEXT:    adcs r5, r0
; CHECK-NEXT:    mov r0, r6
; CHECK-NEXT:    mov r1, r4
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    str r0, [sp, #12] @ 4-byte Spill
; CHECK-NEXT:    str r1, [sp, #16] @ 4-byte Spill
; CHECK-NEXT:    mov r0, r7
; CHECK-NEXT:    mov r1, r5
; CHECK-NEXT:    mov r2, r6
; CHECK-NEXT:    mov r3, r4
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    ldr r2, [sp, #12] @ 4-byte Reload
; CHECK-NEXT:    adds r0, r0, r2
; CHECK-NEXT:    str r0, [sp, #12] @ 4-byte Spill
; CHECK-NEXT:    ldr r0, [sp, #16] @ 4-byte Reload
; CHECK-NEXT:    adcs r0, r1
; CHECK-NEXT:    str r0, [sp, #16] @ 4-byte Spill
; CHECK-NEXT:    movs r7, #0
; CHECK-NEXT:    mov r0, r4
; CHECK-NEXT:    mov r1, r7
; CHECK-NEXT:    mov r2, r6
; CHECK-NEXT:    mov r3, r7
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    str r0, [sp, #4] @ 4-byte Spill
; CHECK-NEXT:    mov r5, r1
; CHECK-NEXT:    mov r0, r6
; CHECK-NEXT:    mov r1, r7
; CHECK-NEXT:    mov r2, r6
; CHECK-NEXT:    mov r3, r7
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    str r0, [sp, #8] @ 4-byte Spill
; CHECK-NEXT:    ldr r0, [sp, #4] @ 4-byte Reload
; CHECK-NEXT:    adds r0, r0, r1
; CHECK-NEXT:    str r0, [sp, #4] @ 4-byte Spill
; CHECK-NEXT:    adcs r5, r7
; CHECK-NEXT:    mov r0, r6
; CHECK-NEXT:    mov r1, r7
; CHECK-NEXT:    mov r2, r4
; CHECK-NEXT:    mov r3, r7
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    ldr r2, [sp, #4] @ 4-byte Reload
; CHECK-NEXT:    adds r0, r0, r2
; CHECK-NEXT:    str r0, [sp, #4] @ 4-byte Spill
; CHECK-NEXT:    adcs r1, r7
; CHECK-NEXT:    adds r6, r5, r1
; CHECK-NEXT:    mov r5, r7
; CHECK-NEXT:    adcs r5, r7
; CHECK-NEXT:    mov r0, r4
; CHECK-NEXT:    mov r1, r7
; CHECK-NEXT:    mov r2, r4
; CHECK-NEXT:    mov r3, r7
; CHECK-NEXT:    bl __aeabi_lmul
; CHECK-NEXT:    adds r0, r0, r6
; CHECK-NEXT:    adcs r5, r1
; CHECK-NEXT:    ldr r1, [sp, #12] @ 4-byte Reload
; CHECK-NEXT:    adds r2, r0, r1
; CHECK-NEXT:    ldr r0, [sp, #16] @ 4-byte Reload
; CHECK-NEXT:    adcs r5, r0
; CHECK-NEXT:    ldr r0, [sp, #8] @ 4-byte Reload
; CHECK-NEXT:    ldr r1, [sp, #4] @ 4-byte Reload
; CHECK-NEXT:    mov r3, r5
; CHECK-NEXT:    add sp, #20
; CHECK-NEXT:    pop {r4, r5, r6, r7, pc}
entry:
  %0 = load i64, ptr %z, align 4
  %conv.i = zext i64 %0 to i128
  %arrayidx1 = getelementptr inbounds i64, ptr %z, i64 2
  %1 = load i64, ptr %arrayidx1, align 4
  %conv.i38 = zext i64 %1 to i128
  %shl.i39 = shl nuw i128 %conv.i38, 64
  %or = or i128 %shl.i39, %conv.i
  %arrayidx3 = getelementptr inbounds i64, ptr %z, i64 1
  %2 = load i64, ptr %arrayidx3, align 4
  %conv.i37 = zext i64 %2 to i128
  %arrayidx5 = getelementptr inbounds i64, ptr %z, i64 3
  %3 = load i64, ptr %arrayidx5, align 4
  %conv.i35 = zext i64 %3 to i128
  %shl.i36 = shl nuw i128 %conv.i35, 64
  %or7 = or i128 %shl.i36, %conv.i37
  %arrayidx10 = getelementptr inbounds i64, ptr %z, i64 4
  %4 = load i64, ptr %arrayidx10, align 4
  %conv.i64 = zext i64 %4 to i128
  %shl.i33 = shl nuw i128 %conv.i64, 64
  %or12 = or i128 %shl.i33, %conv.i
  %arrayidx15 = getelementptr inbounds i64, ptr %z, i64 5
  %5 = load i64, ptr %arrayidx15, align 4
  %conv.i30 = zext i64 %5 to i128
  %shl.i = shl nuw i128 %conv.i30, 64
  %or17 = or i128 %shl.i, %conv.i37
  %add = add i128 %or7, %or
  %add18 = add i128 %or17, %or12
  %mul = mul i128 %add18, %add
  ret i128 %mul
}
